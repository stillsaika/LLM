{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "13710875-ea4b-4f05-8fe6-ed88cea4c247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "url = \"http://localhost:11434/api/generate\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "92b5a41c-54d8-43a2-aaa4-729e479bfbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_response(text, model, size):\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        #\"prompt\": f\"Give me highlights for the following news article in {size} words: {text}. Provide me with just highlights without any your comments\",\n",
    "        \"prompt\": f\"You are a highly accurate summarization tool. Summarize the provided news article in exactly {size} words. Only provide the highlights without any additional commentary or introduction. Ensure the summary is concise and focused on key points. Input: {text}. Output: [Summary in specified number of words]\",\n",
    "        \"stream\": False\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "    if response.status_code == 200:\n",
    "        res = response.text\n",
    "        data = json.loads(res)\n",
    "        val = data['response']\n",
    "        return val\n",
    "    else:\n",
    "        print(\"Error\", response.status_code, response.text)\n",
    "def count(text):\n",
    "    return len(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "40af0ab8-8dd4-4abe-8f78-a5db48b988b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>count</th>\n",
       "      <th>nemotron-mini</th>\n",
       "      <th>gemma2:9b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model-turned-jihadist Sharky Jama has reported...</td>\n",
       "      <td>Melbourne model Sharky Jama has reportedly bee...</td>\n",
       "      <td>55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A New York teen who lost everything in Hurrica...</td>\n",
       "      <td>New York teen Daria Rose lost everything in Hu...</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Media personality Miranda Devine has apologise...</td>\n",
       "      <td>After scoring a try on Friday night, David Poc...</td>\n",
       "      <td>51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A New York man was indicted Wednesday on multi...</td>\n",
       "      <td>Edward Nudel, 41, was indicted Wednesday on mu...</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Magnificent carpets of wild bluebells have spr...</td>\n",
       "      <td>Photographs taken in Micheldever Woods, Hampsh...</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>An Ohio couple have been found dead in an appa...</td>\n",
       "      <td>The couple are in their 50s and from Cleveland...</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Shabana Bibi, died in hospital on Saturday Apr...</td>\n",
       "      <td>Shabana Bibi, 25, died after she suffered burn...</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>A 25-year-old man left brain damaged as a baby...</td>\n",
       "      <td>25-year-old was left brain damaged after docto...</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>The days of filling your car with petrol may b...</td>\n",
       "      <td>Virginia Polytechnic Institute and State Unive...</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>A former air stewardess who was struck down by...</td>\n",
       "      <td>Gemma Flanagan, 31, from Liverpool, was hit by...</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              article  \\\n",
       "0   Model-turned-jihadist Sharky Jama has reported...   \n",
       "1   A New York teen who lost everything in Hurrica...   \n",
       "2   Media personality Miranda Devine has apologise...   \n",
       "3   A New York man was indicted Wednesday on multi...   \n",
       "4   Magnificent carpets of wild bluebells have spr...   \n",
       "..                                                ...   \n",
       "95  An Ohio couple have been found dead in an appa...   \n",
       "96  Shabana Bibi, died in hospital on Saturday Apr...   \n",
       "97  A 25-year-old man left brain damaged as a baby...   \n",
       "98  The days of filling your car with petrol may b...   \n",
       "99  A former air stewardess who was struck down by...   \n",
       "\n",
       "                                           highlights  count  nemotron-mini  \\\n",
       "0   Melbourne model Sharky Jama has reportedly bee...     55            NaN   \n",
       "1   New York teen Daria Rose lost everything in Hu...     57            NaN   \n",
       "2   After scoring a try on Friday night, David Poc...     51            NaN   \n",
       "3   Edward Nudel, 41, was indicted Wednesday on mu...     46            NaN   \n",
       "4   Photographs taken in Micheldever Woods, Hampsh...     59            NaN   \n",
       "..                                                ...    ...            ...   \n",
       "95  The couple are in their 50s and from Cleveland...     43            NaN   \n",
       "96  Shabana Bibi, 25, died after she suffered burn...     57            NaN   \n",
       "97  25-year-old was left brain damaged after docto...     61            NaN   \n",
       "98  Virginia Polytechnic Institute and State Unive...     59            NaN   \n",
       "99  Gemma Flanagan, 31, from Liverpool, was hit by...     50            NaN   \n",
       "\n",
       "    gemma2:9b  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "..        ...  \n",
       "95        NaN  \n",
       "96        NaN  \n",
       "97        NaN  \n",
       "98        NaN  \n",
       "99        NaN  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/home/chatbot/Desktop/sp_data/test.csv').sample(100)[['article','highlights']]\n",
    "data = data.reset_index(drop=True)\n",
    "data['count'] = data['highlights'].apply(count)\n",
    "data['nemotron-mini'] = np.nan\n",
    "data['gemma2:9b'] = np.nan\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "98cc401f-42ce-47ef-91a9-e3c57197f503",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]/tmp/ipykernel_5533/401228928.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value ' Sharky Jama, a model turned jihadist from Melbourne, was reportedly killed while fighting for ISIS (Islamic State) in Syria last year. His family received news of his death on Monday and paid tribute to him on social media platforms.' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data.at[i,model] = llm_response(data.iloc[i]['article'],model,data.iloc[i]['count'])\n",
      "100%|█████████████████████████████████████████| 100/100 [01:01<00:00,  1.64it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(data.shape[0])):\n",
    "    model = 'nemotron-mini'\n",
    "    data.at[i,model] = llm_response(data.iloc[i]['article'],model,data.iloc[i]['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "983aabed-bb47-4498-b8b8-df34377cdcd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]/tmp/ipykernel_5533/715310275.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Sharky Jama, a former Melbourne model, was reportedly killed in Syria while fighting for ISIS. His father confirmed the death, stating he received a call from Syria informing him of his son's passing.  Jama had joined ISIS last year alongside Yusuf Yusuf. The Department of Foreign Affairs warned Australians against traveling to or fighting in Syria and Iraq due to the dangerous security situation. Jama's family and cousins paid tribute to him on social media.  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data.at[i,model] = llm_response(data.iloc[i]['article'],model,data.iloc[i]['count'])\n",
      "100%|█████████████████████████████████████████| 100/100 [02:26<00:00,  1.47s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(data.shape[0])):\n",
    "    model = 'gemma2:9b'\n",
    "    data.at[i,model] = llm_response(data.iloc[i]['article'],model,data.iloc[i]['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f9924df7-57f6-44a7-9317-83d957cd7d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>count</th>\n",
       "      <th>nemotron-mini</th>\n",
       "      <th>gemma2:9b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model-turned-jihadist Sharky Jama has reported...</td>\n",
       "      <td>Melbourne model Sharky Jama has reportedly bee...</td>\n",
       "      <td>55</td>\n",
       "      <td>Sharky Jama, a model turned jihadist from Mel...</td>\n",
       "      <td>Sharky Jama, a former Melbourne model, was rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A New York teen who lost everything in Hurrica...</td>\n",
       "      <td>New York teen Daria Rose lost everything in Hu...</td>\n",
       "      <td>57</td>\n",
       "      <td>Daria Rose, an 18-year-old New York teen who ...</td>\n",
       "      <td>Daria Rose, an 18-year-old from Hempstead, New...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Media personality Miranda Devine has apologise...</td>\n",
       "      <td>After scoring a try on Friday night, David Poc...</td>\n",
       "      <td>51</td>\n",
       "      <td>Miranda Devine apologized for calling David P...</td>\n",
       "      <td>Miranda Devine called rugby player David Pococ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A New York man was indicted Wednesday on multi...</td>\n",
       "      <td>Edward Nudel, 41, was indicted Wednesday on mu...</td>\n",
       "      <td>46</td>\n",
       "      <td>New York man indicted for strangling relative...</td>\n",
       "      <td>Edward Nudel strangled his relative's 2-year-o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Magnificent carpets of wild bluebells have spr...</td>\n",
       "      <td>Photographs taken in Micheldever Woods, Hampsh...</td>\n",
       "      <td>59</td>\n",
       "      <td>Stunning carpets of wild bluebells have bloss...</td>\n",
       "      <td>Wild bluebells are blooming weeks ahead of sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>An Ohio couple have been found dead in an appa...</td>\n",
       "      <td>The couple are in their 50s and from Cleveland...</td>\n",
       "      <td>43</td>\n",
       "      <td>An Ohio couple died in an apparent murder-sui...</td>\n",
       "      <td>A couple from Cleveland, Ohio, were found dead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Shabana Bibi, died in hospital on Saturday Apr...</td>\n",
       "      <td>Shabana Bibi, 25, died after she suffered burn...</td>\n",
       "      <td>57</td>\n",
       "      <td>Shabana Bibi was found dead after suffering b...</td>\n",
       "      <td>Shabana Bibi, 25, died from burns covering 80%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>A 25-year-old man left brain damaged as a baby...</td>\n",
       "      <td>25-year-old was left brain damaged after docto...</td>\n",
       "      <td>61</td>\n",
       "      <td>A man brain damaged as a baby after doctors f...</td>\n",
       "      <td>A 25-year-old man with brain damage sustained ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>The days of filling your car with petrol may b...</td>\n",
       "      <td>Virginia Polytechnic Institute and State Unive...</td>\n",
       "      <td>59</td>\n",
       "      <td>US scientists have developed a method using p...</td>\n",
       "      <td>US researchers have developed a method to effi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>A former air stewardess who was struck down by...</td>\n",
       "      <td>Gemma Flanagan, 31, from Liverpool, was hit by...</td>\n",
       "      <td>50</td>\n",
       "      <td>Former air stewardess Gemma Flanagan made her...</td>\n",
       "      <td>Gemma Flanagan, a former air stewardess, was p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              article  \\\n",
       "0   Model-turned-jihadist Sharky Jama has reported...   \n",
       "1   A New York teen who lost everything in Hurrica...   \n",
       "2   Media personality Miranda Devine has apologise...   \n",
       "3   A New York man was indicted Wednesday on multi...   \n",
       "4   Magnificent carpets of wild bluebells have spr...   \n",
       "..                                                ...   \n",
       "95  An Ohio couple have been found dead in an appa...   \n",
       "96  Shabana Bibi, died in hospital on Saturday Apr...   \n",
       "97  A 25-year-old man left brain damaged as a baby...   \n",
       "98  The days of filling your car with petrol may b...   \n",
       "99  A former air stewardess who was struck down by...   \n",
       "\n",
       "                                           highlights  count  \\\n",
       "0   Melbourne model Sharky Jama has reportedly bee...     55   \n",
       "1   New York teen Daria Rose lost everything in Hu...     57   \n",
       "2   After scoring a try on Friday night, David Poc...     51   \n",
       "3   Edward Nudel, 41, was indicted Wednesday on mu...     46   \n",
       "4   Photographs taken in Micheldever Woods, Hampsh...     59   \n",
       "..                                                ...    ...   \n",
       "95  The couple are in their 50s and from Cleveland...     43   \n",
       "96  Shabana Bibi, 25, died after she suffered burn...     57   \n",
       "97  25-year-old was left brain damaged after docto...     61   \n",
       "98  Virginia Polytechnic Institute and State Unive...     59   \n",
       "99  Gemma Flanagan, 31, from Liverpool, was hit by...     50   \n",
       "\n",
       "                                        nemotron-mini  \\\n",
       "0    Sharky Jama, a model turned jihadist from Mel...   \n",
       "1    Daria Rose, an 18-year-old New York teen who ...   \n",
       "2    Miranda Devine apologized for calling David P...   \n",
       "3    New York man indicted for strangling relative...   \n",
       "4    Stunning carpets of wild bluebells have bloss...   \n",
       "..                                                ...   \n",
       "95   An Ohio couple died in an apparent murder-sui...   \n",
       "96   Shabana Bibi was found dead after suffering b...   \n",
       "97   A man brain damaged as a baby after doctors f...   \n",
       "98   US scientists have developed a method using p...   \n",
       "99   Former air stewardess Gemma Flanagan made her...   \n",
       "\n",
       "                                            gemma2:9b  \n",
       "0   Sharky Jama, a former Melbourne model, was rep...  \n",
       "1   Daria Rose, an 18-year-old from Hempstead, New...  \n",
       "2   Miranda Devine called rugby player David Pococ...  \n",
       "3   Edward Nudel strangled his relative's 2-year-o...  \n",
       "4   Wild bluebells are blooming weeks ahead of sch...  \n",
       "..                                                ...  \n",
       "95  A couple from Cleveland, Ohio, were found dead...  \n",
       "96  Shabana Bibi, 25, died from burns covering 80%...  \n",
       "97  A 25-year-old man with brain damage sustained ...  \n",
       "98  US researchers have developed a method to effi...  \n",
       "99  Gemma Flanagan, a former air stewardess, was p...  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "24c99a3b-1b61-45ce-95ab-7f980e9f473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('small_llms_eval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "404d181b-5347-4e7e-bbf2-8a9c8acf85e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>count</th>\n",
       "      <th>nemotron-mini</th>\n",
       "      <th>gemma2:9b</th>\n",
       "      <th>nemotron</th>\n",
       "      <th>gemma2:27b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model-turned-jihadist Sharky Jama has reported...</td>\n",
       "      <td>Melbourne model Sharky Jama has reportedly bee...</td>\n",
       "      <td>55</td>\n",
       "      <td>Sharky Jama, a model turned jihadist from Mel...</td>\n",
       "      <td>Sharky Jama, a former Melbourne model, was rep...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A New York teen who lost everything in Hurrica...</td>\n",
       "      <td>New York teen Daria Rose lost everything in Hu...</td>\n",
       "      <td>57</td>\n",
       "      <td>Daria Rose, an 18-year-old New York teen who ...</td>\n",
       "      <td>Daria Rose, an 18-year-old from Hempstead, New...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Media personality Miranda Devine has apologise...</td>\n",
       "      <td>After scoring a try on Friday night, David Poc...</td>\n",
       "      <td>51</td>\n",
       "      <td>Miranda Devine apologized for calling David P...</td>\n",
       "      <td>Miranda Devine called rugby player David Pococ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A New York man was indicted Wednesday on multi...</td>\n",
       "      <td>Edward Nudel, 41, was indicted Wednesday on mu...</td>\n",
       "      <td>46</td>\n",
       "      <td>New York man indicted for strangling relative...</td>\n",
       "      <td>Edward Nudel strangled his relative's 2-year-o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Magnificent carpets of wild bluebells have spr...</td>\n",
       "      <td>Photographs taken in Micheldever Woods, Hampsh...</td>\n",
       "      <td>59</td>\n",
       "      <td>Stunning carpets of wild bluebells have bloss...</td>\n",
       "      <td>Wild bluebells are blooming weeks ahead of sch...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>An Ohio couple have been found dead in an appa...</td>\n",
       "      <td>The couple are in their 50s and from Cleveland...</td>\n",
       "      <td>43</td>\n",
       "      <td>An Ohio couple died in an apparent murder-sui...</td>\n",
       "      <td>A couple from Cleveland, Ohio, were found dead...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Shabana Bibi, died in hospital on Saturday Apr...</td>\n",
       "      <td>Shabana Bibi, 25, died after she suffered burn...</td>\n",
       "      <td>57</td>\n",
       "      <td>Shabana Bibi was found dead after suffering b...</td>\n",
       "      <td>Shabana Bibi, 25, died from burns covering 80%...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>A 25-year-old man left brain damaged as a baby...</td>\n",
       "      <td>25-year-old was left brain damaged after docto...</td>\n",
       "      <td>61</td>\n",
       "      <td>A man brain damaged as a baby after doctors f...</td>\n",
       "      <td>A 25-year-old man with brain damage sustained ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>The days of filling your car with petrol may b...</td>\n",
       "      <td>Virginia Polytechnic Institute and State Unive...</td>\n",
       "      <td>59</td>\n",
       "      <td>US scientists have developed a method using p...</td>\n",
       "      <td>US researchers have developed a method to effi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>A former air stewardess who was struck down by...</td>\n",
       "      <td>Gemma Flanagan, 31, from Liverpool, was hit by...</td>\n",
       "      <td>50</td>\n",
       "      <td>Former air stewardess Gemma Flanagan made her...</td>\n",
       "      <td>Gemma Flanagan, a former air stewardess, was p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              article  \\\n",
       "0   Model-turned-jihadist Sharky Jama has reported...   \n",
       "1   A New York teen who lost everything in Hurrica...   \n",
       "2   Media personality Miranda Devine has apologise...   \n",
       "3   A New York man was indicted Wednesday on multi...   \n",
       "4   Magnificent carpets of wild bluebells have spr...   \n",
       "..                                                ...   \n",
       "95  An Ohio couple have been found dead in an appa...   \n",
       "96  Shabana Bibi, died in hospital on Saturday Apr...   \n",
       "97  A 25-year-old man left brain damaged as a baby...   \n",
       "98  The days of filling your car with petrol may b...   \n",
       "99  A former air stewardess who was struck down by...   \n",
       "\n",
       "                                           highlights  count  \\\n",
       "0   Melbourne model Sharky Jama has reportedly bee...     55   \n",
       "1   New York teen Daria Rose lost everything in Hu...     57   \n",
       "2   After scoring a try on Friday night, David Poc...     51   \n",
       "3   Edward Nudel, 41, was indicted Wednesday on mu...     46   \n",
       "4   Photographs taken in Micheldever Woods, Hampsh...     59   \n",
       "..                                                ...    ...   \n",
       "95  The couple are in their 50s and from Cleveland...     43   \n",
       "96  Shabana Bibi, 25, died after she suffered burn...     57   \n",
       "97  25-year-old was left brain damaged after docto...     61   \n",
       "98  Virginia Polytechnic Institute and State Unive...     59   \n",
       "99  Gemma Flanagan, 31, from Liverpool, was hit by...     50   \n",
       "\n",
       "                                        nemotron-mini  \\\n",
       "0    Sharky Jama, a model turned jihadist from Mel...   \n",
       "1    Daria Rose, an 18-year-old New York teen who ...   \n",
       "2    Miranda Devine apologized for calling David P...   \n",
       "3    New York man indicted for strangling relative...   \n",
       "4    Stunning carpets of wild bluebells have bloss...   \n",
       "..                                                ...   \n",
       "95   An Ohio couple died in an apparent murder-sui...   \n",
       "96   Shabana Bibi was found dead after suffering b...   \n",
       "97   A man brain damaged as a baby after doctors f...   \n",
       "98   US scientists have developed a method using p...   \n",
       "99   Former air stewardess Gemma Flanagan made her...   \n",
       "\n",
       "                                            gemma2:9b  nemotron  gemma2:27b  \n",
       "0   Sharky Jama, a former Melbourne model, was rep...       NaN         NaN  \n",
       "1   Daria Rose, an 18-year-old from Hempstead, New...       NaN         NaN  \n",
       "2   Miranda Devine called rugby player David Pococ...       NaN         NaN  \n",
       "3   Edward Nudel strangled his relative's 2-year-o...       NaN         NaN  \n",
       "4   Wild bluebells are blooming weeks ahead of sch...       NaN         NaN  \n",
       "..                                                ...       ...         ...  \n",
       "95  A couple from Cleveland, Ohio, were found dead...       NaN         NaN  \n",
       "96  Shabana Bibi, 25, died from burns covering 80%...       NaN         NaN  \n",
       "97  A 25-year-old man with brain damage sustained ...       NaN         NaN  \n",
       "98  US researchers have developed a method to effi...       NaN         NaN  \n",
       "99  Gemma Flanagan, a former air stewardess, was p...       NaN         NaN  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['nemotron'] = np.nan\n",
    "data['gemma2:27b'] = np.nan\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d2d06e2b-97ab-436b-8b44-3cf8ea211ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]/tmp/ipykernel_5533/1179434898.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Here is a summary of the news article in exactly 55 words:\n",
      "\n",
      "Melbourne model Sharky Jama, who joined Islamic State (IS) last year, has been killed in Syria. His father, Dada Jama, confirmed the death via text message and phone call. Tributes flooded social media. The Australian government couldn't confirm due to \"extremely limited\" capacity, warning Australians to leave conflict zones.' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data.at[i,model] = llm_response(data.iloc[i]['article'],model,data.iloc[i]['count'])\n",
      "100%|█████████████████████████████████████████| 100/100 [09:17<00:00,  5.58s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(data.shape[0])):\n",
    "    model = 'nemotron'\n",
    "    data.at[i,model] = llm_response(data.iloc[i]['article'],model,data.iloc[i]['count'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "22d223aa-7550-449f-9f73-b47dc04aedc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]/tmp/ipykernel_5533/2846124162.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Sharky Jama, a former Melbourne model, has reportedly been killed fighting for ISIS in Syria. His father confirmed the news after receiving messages from friends. The Department of Foreign Affairs cannot confirm the death due to the dangerous situation in Syria. Jama fled to Syria with his friend Yusuf Yusuf last year to join ISIS.  His family and cousins paid tribute to him on social media. \n",
      "\n",
      "\n",
      "' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data.at[i,model] = llm_response(data.iloc[i]['article'],model,data.iloc[i]['count'])\n",
      "100%|█████████████████████████████████████████| 100/100 [04:36<00:00,  2.77s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(data.shape[0])):\n",
    "    model = 'gemma2:27b'\n",
    "    data.at[i,model] = llm_response(data.iloc[i]['article'],model,data.iloc[i]['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "48216dfe-611e-412a-b067-7f901ce0eb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('small_big_llms_eval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "23c68543-f3e2-4cac-b0eb-e465e3a5eda9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>count</th>\n",
       "      <th>nemotron-mini</th>\n",
       "      <th>gemma2:9b</th>\n",
       "      <th>nemotron</th>\n",
       "      <th>gemma2:27b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model-turned-jihadist Sharky Jama has reported...</td>\n",
       "      <td>Melbourne model Sharky Jama has reportedly bee...</td>\n",
       "      <td>55</td>\n",
       "      <td>Sharky Jama, a model turned jihadist from Mel...</td>\n",
       "      <td>Sharky Jama, a former Melbourne model, was rep...</td>\n",
       "      <td>Here is a summary of the news article in exact...</td>\n",
       "      <td>Sharky Jama, a former Melbourne model, has rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A New York teen who lost everything in Hurrica...</td>\n",
       "      <td>New York teen Daria Rose lost everything in Hu...</td>\n",
       "      <td>57</td>\n",
       "      <td>Daria Rose, an 18-year-old New York teen who ...</td>\n",
       "      <td>Daria Rose, an 18-year-old from Hempstead, New...</td>\n",
       "      <td>Here is a summary of the news article in exact...</td>\n",
       "      <td>Daria Rose, an 18-year-old from Hempstead, New...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Media personality Miranda Devine has apologise...</td>\n",
       "      <td>After scoring a try on Friday night, David Poc...</td>\n",
       "      <td>51</td>\n",
       "      <td>Miranda Devine apologized for calling David P...</td>\n",
       "      <td>Miranda Devine called rugby player David Pococ...</td>\n",
       "      <td>Here is the summary in exactly 51 words:\\n\\nMe...</td>\n",
       "      <td>Miranda Devine apologized for calling rugby pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A New York man was indicted Wednesday on multi...</td>\n",
       "      <td>Edward Nudel, 41, was indicted Wednesday on mu...</td>\n",
       "      <td>46</td>\n",
       "      <td>New York man indicted for strangling relative...</td>\n",
       "      <td>Edward Nudel strangled his relative's 2-year-o...</td>\n",
       "      <td>Here is a summary of the news article in exact...</td>\n",
       "      <td>Edward Nudel, 41, was indicted for strangling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Magnificent carpets of wild bluebells have spr...</td>\n",
       "      <td>Photographs taken in Micheldever Woods, Hampsh...</td>\n",
       "      <td>59</td>\n",
       "      <td>Stunning carpets of wild bluebells have bloss...</td>\n",
       "      <td>Wild bluebells are blooming weeks ahead of sch...</td>\n",
       "      <td>Here is the summary in exactly 59 words:\\n\\n\"U...</td>\n",
       "      <td>Wild bluebells are blooming weeks early in Eng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>An Ohio couple have been found dead in an appa...</td>\n",
       "      <td>The couple are in their 50s and from Cleveland...</td>\n",
       "      <td>43</td>\n",
       "      <td>An Ohio couple died in an apparent murder-sui...</td>\n",
       "      <td>A couple from Cleveland, Ohio, were found dead...</td>\n",
       "      <td>Here is the summary in exactly 43 words:\\n\\n\"O...</td>\n",
       "      <td>An Ohio couple in their 50s were found dead in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Shabana Bibi, died in hospital on Saturday Apr...</td>\n",
       "      <td>Shabana Bibi, 25, died after she suffered burn...</td>\n",
       "      <td>57</td>\n",
       "      <td>Shabana Bibi was found dead after suffering b...</td>\n",
       "      <td>Shabana Bibi, 25, died from burns covering 80%...</td>\n",
       "      <td>Here is the summary in exactly 57 words:\\n\\nSh...</td>\n",
       "      <td>Shabana Bibi, 25, died from burns after allege...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>A 25-year-old man left brain damaged as a baby...</td>\n",
       "      <td>25-year-old was left brain damaged after docto...</td>\n",
       "      <td>61</td>\n",
       "      <td>A man brain damaged as a baby after doctors f...</td>\n",
       "      <td>A 25-year-old man with brain damage sustained ...</td>\n",
       "      <td>Here is the summary in exactly 61 words:\\n\\n\"A...</td>\n",
       "      <td>A 25-year-old man has won a £7.3 million compe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>The days of filling your car with petrol may b...</td>\n",
       "      <td>Virginia Polytechnic Institute and State Unive...</td>\n",
       "      <td>59</td>\n",
       "      <td>US scientists have developed a method using p...</td>\n",
       "      <td>US researchers have developed a method to effi...</td>\n",
       "      <td>Here is the summary in exactly 59 words:\\n\\n\"U...</td>\n",
       "      <td>US scientists have developed a method to effic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>A former air stewardess who was struck down by...</td>\n",
       "      <td>Gemma Flanagan, 31, from Liverpool, was hit by...</td>\n",
       "      <td>50</td>\n",
       "      <td>Former air stewardess Gemma Flanagan made her...</td>\n",
       "      <td>Gemma Flanagan, a former air stewardess, was p...</td>\n",
       "      <td>Here is the summary in exactly 50 words:\\n\\nGe...</td>\n",
       "      <td>Gemma Flanagan, a former air stewardess, will ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              article  \\\n",
       "0   Model-turned-jihadist Sharky Jama has reported...   \n",
       "1   A New York teen who lost everything in Hurrica...   \n",
       "2   Media personality Miranda Devine has apologise...   \n",
       "3   A New York man was indicted Wednesday on multi...   \n",
       "4   Magnificent carpets of wild bluebells have spr...   \n",
       "..                                                ...   \n",
       "95  An Ohio couple have been found dead in an appa...   \n",
       "96  Shabana Bibi, died in hospital on Saturday Apr...   \n",
       "97  A 25-year-old man left brain damaged as a baby...   \n",
       "98  The days of filling your car with petrol may b...   \n",
       "99  A former air stewardess who was struck down by...   \n",
       "\n",
       "                                           highlights  count  \\\n",
       "0   Melbourne model Sharky Jama has reportedly bee...     55   \n",
       "1   New York teen Daria Rose lost everything in Hu...     57   \n",
       "2   After scoring a try on Friday night, David Poc...     51   \n",
       "3   Edward Nudel, 41, was indicted Wednesday on mu...     46   \n",
       "4   Photographs taken in Micheldever Woods, Hampsh...     59   \n",
       "..                                                ...    ...   \n",
       "95  The couple are in their 50s and from Cleveland...     43   \n",
       "96  Shabana Bibi, 25, died after she suffered burn...     57   \n",
       "97  25-year-old was left brain damaged after docto...     61   \n",
       "98  Virginia Polytechnic Institute and State Unive...     59   \n",
       "99  Gemma Flanagan, 31, from Liverpool, was hit by...     50   \n",
       "\n",
       "                                        nemotron-mini  \\\n",
       "0    Sharky Jama, a model turned jihadist from Mel...   \n",
       "1    Daria Rose, an 18-year-old New York teen who ...   \n",
       "2    Miranda Devine apologized for calling David P...   \n",
       "3    New York man indicted for strangling relative...   \n",
       "4    Stunning carpets of wild bluebells have bloss...   \n",
       "..                                                ...   \n",
       "95   An Ohio couple died in an apparent murder-sui...   \n",
       "96   Shabana Bibi was found dead after suffering b...   \n",
       "97   A man brain damaged as a baby after doctors f...   \n",
       "98   US scientists have developed a method using p...   \n",
       "99   Former air stewardess Gemma Flanagan made her...   \n",
       "\n",
       "                                            gemma2:9b  \\\n",
       "0   Sharky Jama, a former Melbourne model, was rep...   \n",
       "1   Daria Rose, an 18-year-old from Hempstead, New...   \n",
       "2   Miranda Devine called rugby player David Pococ...   \n",
       "3   Edward Nudel strangled his relative's 2-year-o...   \n",
       "4   Wild bluebells are blooming weeks ahead of sch...   \n",
       "..                                                ...   \n",
       "95  A couple from Cleveland, Ohio, were found dead...   \n",
       "96  Shabana Bibi, 25, died from burns covering 80%...   \n",
       "97  A 25-year-old man with brain damage sustained ...   \n",
       "98  US researchers have developed a method to effi...   \n",
       "99  Gemma Flanagan, a former air stewardess, was p...   \n",
       "\n",
       "                                             nemotron  \\\n",
       "0   Here is a summary of the news article in exact...   \n",
       "1   Here is a summary of the news article in exact...   \n",
       "2   Here is the summary in exactly 51 words:\\n\\nMe...   \n",
       "3   Here is a summary of the news article in exact...   \n",
       "4   Here is the summary in exactly 59 words:\\n\\n\"U...   \n",
       "..                                                ...   \n",
       "95  Here is the summary in exactly 43 words:\\n\\n\"O...   \n",
       "96  Here is the summary in exactly 57 words:\\n\\nSh...   \n",
       "97  Here is the summary in exactly 61 words:\\n\\n\"A...   \n",
       "98  Here is the summary in exactly 59 words:\\n\\n\"U...   \n",
       "99  Here is the summary in exactly 50 words:\\n\\nGe...   \n",
       "\n",
       "                                           gemma2:27b  \n",
       "0   Sharky Jama, a former Melbourne model, has rep...  \n",
       "1   Daria Rose, an 18-year-old from Hempstead, New...  \n",
       "2   Miranda Devine apologized for calling rugby pl...  \n",
       "3   Edward Nudel, 41, was indicted for strangling ...  \n",
       "4   Wild bluebells are blooming weeks early in Eng...  \n",
       "..                                                ...  \n",
       "95  An Ohio couple in their 50s were found dead in...  \n",
       "96  Shabana Bibi, 25, died from burns after allege...  \n",
       "97  A 25-year-old man has won a £7.3 million compe...  \n",
       "98  US scientists have developed a method to effic...  \n",
       "99  Gemma Flanagan, a former air stewardess, will ...  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "98df546a-2f22-41a3-9dcc-c27db5958049",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['nemotron'].iloc[0].split('\\n\\n')[-1]\n",
    "def corr(text):\n",
    "    return text.split('\\n\\n')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9ecfa37b-c25f-4173-bf94-a9f2e2ccda9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>count</th>\n",
       "      <th>nemotron-mini</th>\n",
       "      <th>gemma2:9b</th>\n",
       "      <th>nemotron</th>\n",
       "      <th>gemma2:27b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model-turned-jihadist Sharky Jama has reported...</td>\n",
       "      <td>Melbourne model Sharky Jama has reportedly bee...</td>\n",
       "      <td>55</td>\n",
       "      <td>Sharky Jama, a model turned jihadist from Mel...</td>\n",
       "      <td>Sharky Jama, a former Melbourne model, was rep...</td>\n",
       "      <td>Melbourne model Sharky Jama, who joined Islami...</td>\n",
       "      <td>Sharky Jama, a former Melbourne model, has rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A New York teen who lost everything in Hurrica...</td>\n",
       "      <td>New York teen Daria Rose lost everything in Hu...</td>\n",
       "      <td>57</td>\n",
       "      <td>Daria Rose, an 18-year-old New York teen who ...</td>\n",
       "      <td>Daria Rose, an 18-year-old from Hempstead, New...</td>\n",
       "      <td>Daria Rose, 18, accepted into all 7 Ivy League...</td>\n",
       "      <td>Daria Rose, an 18-year-old from Hempstead, New...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Media personality Miranda Devine has apologise...</td>\n",
       "      <td>After scoring a try on Friday night, David Poc...</td>\n",
       "      <td>51</td>\n",
       "      <td>Miranda Devine apologized for calling David P...</td>\n",
       "      <td>Miranda Devine called rugby player David Pococ...</td>\n",
       "      <td>Media personality Miranda Devine apologized fo...</td>\n",
       "      <td>Miranda Devine apologized for calling rugby pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A New York man was indicted Wednesday on multi...</td>\n",
       "      <td>Edward Nudel, 41, was indicted Wednesday on mu...</td>\n",
       "      <td>46</td>\n",
       "      <td>New York man indicted for strangling relative...</td>\n",
       "      <td>Edward Nudel strangled his relative's 2-year-o...</td>\n",
       "      <td>\"Edward Nudel, 41, indicted for strangling rel...</td>\n",
       "      <td>Edward Nudel, 41, was indicted for strangling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Magnificent carpets of wild bluebells have spr...</td>\n",
       "      <td>Photographs taken in Micheldever Woods, Hampsh...</td>\n",
       "      <td>59</td>\n",
       "      <td>Stunning carpets of wild bluebells have bloss...</td>\n",
       "      <td>Wild bluebells are blooming weeks ahead of sch...</td>\n",
       "      <td>\"UK's balmy spring weather brings early bloom ...</td>\n",
       "      <td>Wild bluebells are blooming weeks early in Eng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>An Ohio couple have been found dead in an appa...</td>\n",
       "      <td>The couple are in their 50s and from Cleveland...</td>\n",
       "      <td>43</td>\n",
       "      <td>An Ohio couple died in an apparent murder-sui...</td>\n",
       "      <td>A couple from Cleveland, Ohio, were found dead...</td>\n",
       "      <td>\"Ohio couple (both in their 50s from Cleveland...</td>\n",
       "      <td>An Ohio couple in their 50s were found dead in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Shabana Bibi, died in hospital on Saturday Apr...</td>\n",
       "      <td>Shabana Bibi, 25, died after she suffered burn...</td>\n",
       "      <td>57</td>\n",
       "      <td>Shabana Bibi was found dead after suffering b...</td>\n",
       "      <td>Shabana Bibi, 25, died from burns covering 80%...</td>\n",
       "      <td>Shabana Bibi, 25, died from 80% burns after al...</td>\n",
       "      <td>Shabana Bibi, 25, died from burns after allege...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>A 25-year-old man left brain damaged as a baby...</td>\n",
       "      <td>25-year-old was left brain damaged after docto...</td>\n",
       "      <td>61</td>\n",
       "      <td>A man brain damaged as a baby after doctors f...</td>\n",
       "      <td>A 25-year-old man with brain damage sustained ...</td>\n",
       "      <td>\"A 25-year-old man, left brain damaged as a ba...</td>\n",
       "      <td>A 25-year-old man has won a £7.3 million compe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>The days of filling your car with petrol may b...</td>\n",
       "      <td>Virginia Polytechnic Institute and State Unive...</td>\n",
       "      <td>59</td>\n",
       "      <td>US scientists have developed a method using p...</td>\n",
       "      <td>US researchers have developed a method to effi...</td>\n",
       "      <td>\"US scientists have boosted efficiency in prod...</td>\n",
       "      <td>US scientists have developed a method to effic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>A former air stewardess who was struck down by...</td>\n",
       "      <td>Gemma Flanagan, 31, from Liverpool, was hit by...</td>\n",
       "      <td>50</td>\n",
       "      <td>Former air stewardess Gemma Flanagan made her...</td>\n",
       "      <td>Gemma Flanagan, a former air stewardess, was p...</td>\n",
       "      <td>Gemma Flanagan, 31, a former British Airways s...</td>\n",
       "      <td>Gemma Flanagan, a former air stewardess, will ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              article  \\\n",
       "0   Model-turned-jihadist Sharky Jama has reported...   \n",
       "1   A New York teen who lost everything in Hurrica...   \n",
       "2   Media personality Miranda Devine has apologise...   \n",
       "3   A New York man was indicted Wednesday on multi...   \n",
       "4   Magnificent carpets of wild bluebells have spr...   \n",
       "..                                                ...   \n",
       "95  An Ohio couple have been found dead in an appa...   \n",
       "96  Shabana Bibi, died in hospital on Saturday Apr...   \n",
       "97  A 25-year-old man left brain damaged as a baby...   \n",
       "98  The days of filling your car with petrol may b...   \n",
       "99  A former air stewardess who was struck down by...   \n",
       "\n",
       "                                           highlights  count  \\\n",
       "0   Melbourne model Sharky Jama has reportedly bee...     55   \n",
       "1   New York teen Daria Rose lost everything in Hu...     57   \n",
       "2   After scoring a try on Friday night, David Poc...     51   \n",
       "3   Edward Nudel, 41, was indicted Wednesday on mu...     46   \n",
       "4   Photographs taken in Micheldever Woods, Hampsh...     59   \n",
       "..                                                ...    ...   \n",
       "95  The couple are in their 50s and from Cleveland...     43   \n",
       "96  Shabana Bibi, 25, died after she suffered burn...     57   \n",
       "97  25-year-old was left brain damaged after docto...     61   \n",
       "98  Virginia Polytechnic Institute and State Unive...     59   \n",
       "99  Gemma Flanagan, 31, from Liverpool, was hit by...     50   \n",
       "\n",
       "                                        nemotron-mini  \\\n",
       "0    Sharky Jama, a model turned jihadist from Mel...   \n",
       "1    Daria Rose, an 18-year-old New York teen who ...   \n",
       "2    Miranda Devine apologized for calling David P...   \n",
       "3    New York man indicted for strangling relative...   \n",
       "4    Stunning carpets of wild bluebells have bloss...   \n",
       "..                                                ...   \n",
       "95   An Ohio couple died in an apparent murder-sui...   \n",
       "96   Shabana Bibi was found dead after suffering b...   \n",
       "97   A man brain damaged as a baby after doctors f...   \n",
       "98   US scientists have developed a method using p...   \n",
       "99   Former air stewardess Gemma Flanagan made her...   \n",
       "\n",
       "                                            gemma2:9b  \\\n",
       "0   Sharky Jama, a former Melbourne model, was rep...   \n",
       "1   Daria Rose, an 18-year-old from Hempstead, New...   \n",
       "2   Miranda Devine called rugby player David Pococ...   \n",
       "3   Edward Nudel strangled his relative's 2-year-o...   \n",
       "4   Wild bluebells are blooming weeks ahead of sch...   \n",
       "..                                                ...   \n",
       "95  A couple from Cleveland, Ohio, were found dead...   \n",
       "96  Shabana Bibi, 25, died from burns covering 80%...   \n",
       "97  A 25-year-old man with brain damage sustained ...   \n",
       "98  US researchers have developed a method to effi...   \n",
       "99  Gemma Flanagan, a former air stewardess, was p...   \n",
       "\n",
       "                                             nemotron  \\\n",
       "0   Melbourne model Sharky Jama, who joined Islami...   \n",
       "1   Daria Rose, 18, accepted into all 7 Ivy League...   \n",
       "2   Media personality Miranda Devine apologized fo...   \n",
       "3   \"Edward Nudel, 41, indicted for strangling rel...   \n",
       "4   \"UK's balmy spring weather brings early bloom ...   \n",
       "..                                                ...   \n",
       "95  \"Ohio couple (both in their 50s from Cleveland...   \n",
       "96  Shabana Bibi, 25, died from 80% burns after al...   \n",
       "97  \"A 25-year-old man, left brain damaged as a ba...   \n",
       "98  \"US scientists have boosted efficiency in prod...   \n",
       "99  Gemma Flanagan, 31, a former British Airways s...   \n",
       "\n",
       "                                           gemma2:27b  \n",
       "0   Sharky Jama, a former Melbourne model, has rep...  \n",
       "1   Daria Rose, an 18-year-old from Hempstead, New...  \n",
       "2   Miranda Devine apologized for calling rugby pl...  \n",
       "3   Edward Nudel, 41, was indicted for strangling ...  \n",
       "4   Wild bluebells are blooming weeks early in Eng...  \n",
       "..                                                ...  \n",
       "95  An Ohio couple in their 50s were found dead in...  \n",
       "96  Shabana Bibi, 25, died from burns after allege...  \n",
       "97  A 25-year-old man has won a £7.3 million compe...  \n",
       "98  US scientists have developed a method to effic...  \n",
       "99  Gemma Flanagan, a former air stewardess, will ...  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['nemotron'] = data['nemotron'].apply(corr)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b6a222b7-38f2-4c10-b9ca-f455a2004031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"A 25-year-old man, left brain damaged as a baby due to a doctor\\'s blunder at Luton and Dunstable Hospital, has won a £7.3 million compensation after a 23-year battle. He was denied a vitamin K injection at birth, leading to a brain haemorrhage. The settlement includes a £2.345m lump sum and annual payments of up to £192,000.\"'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['nemotron'].iloc[97]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3f60a9d5-c2e7-417f-b850-8a6fdfba1b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>count</th>\n",
       "      <th>nemotron-mini</th>\n",
       "      <th>gemma2:9b</th>\n",
       "      <th>nemotron</th>\n",
       "      <th>gemma2:27b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model-turned-jihadist Sharky Jama has reported...</td>\n",
       "      <td>Melbourne model Sharky Jama has reportedly bee...</td>\n",
       "      <td>55</td>\n",
       "      <td>Sharky Jama, a model turned jihadist from Mel...</td>\n",
       "      <td>Sharky Jama, a former Melbourne model, was rep...</td>\n",
       "      <td>Melbourne model Sharky Jama, who joined Islami...</td>\n",
       "      <td>Sharky Jama, a former Melbourne model, has rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A New York teen who lost everything in Hurrica...</td>\n",
       "      <td>New York teen Daria Rose lost everything in Hu...</td>\n",
       "      <td>57</td>\n",
       "      <td>Daria Rose, an 18-year-old New York teen who ...</td>\n",
       "      <td>Daria Rose, an 18-year-old from Hempstead, New...</td>\n",
       "      <td>Daria Rose, 18, accepted into all 7 Ivy League...</td>\n",
       "      <td>Daria Rose, an 18-year-old from Hempstead, New...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Media personality Miranda Devine has apologise...</td>\n",
       "      <td>After scoring a try on Friday night, David Poc...</td>\n",
       "      <td>51</td>\n",
       "      <td>Miranda Devine apologized for calling David P...</td>\n",
       "      <td>Miranda Devine called rugby player David Pococ...</td>\n",
       "      <td>Media personality Miranda Devine apologized fo...</td>\n",
       "      <td>Miranda Devine apologized for calling rugby pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A New York man was indicted Wednesday on multi...</td>\n",
       "      <td>Edward Nudel, 41, was indicted Wednesday on mu...</td>\n",
       "      <td>46</td>\n",
       "      <td>New York man indicted for strangling relative...</td>\n",
       "      <td>Edward Nudel strangled his relative's 2-year-o...</td>\n",
       "      <td>Edward Nudel, 41, indicted for strangling rela...</td>\n",
       "      <td>Edward Nudel, 41, was indicted for strangling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Magnificent carpets of wild bluebells have spr...</td>\n",
       "      <td>Photographs taken in Micheldever Woods, Hampsh...</td>\n",
       "      <td>59</td>\n",
       "      <td>Stunning carpets of wild bluebells have bloss...</td>\n",
       "      <td>Wild bluebells are blooming weeks ahead of sch...</td>\n",
       "      <td>UK's balmy spring weather brings early bloom t...</td>\n",
       "      <td>Wild bluebells are blooming weeks early in Eng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>An Ohio couple have been found dead in an appa...</td>\n",
       "      <td>The couple are in their 50s and from Cleveland...</td>\n",
       "      <td>43</td>\n",
       "      <td>An Ohio couple died in an apparent murder-sui...</td>\n",
       "      <td>A couple from Cleveland, Ohio, were found dead...</td>\n",
       "      <td>Ohio couple (both in their 50s from Cleveland)...</td>\n",
       "      <td>An Ohio couple in their 50s were found dead in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Shabana Bibi, died in hospital on Saturday Apr...</td>\n",
       "      <td>Shabana Bibi, 25, died after she suffered burn...</td>\n",
       "      <td>57</td>\n",
       "      <td>Shabana Bibi was found dead after suffering b...</td>\n",
       "      <td>Shabana Bibi, 25, died from burns covering 80%...</td>\n",
       "      <td>Shabana Bibi, 25, died from 80% burns after al...</td>\n",
       "      <td>Shabana Bibi, 25, died from burns after allege...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>A 25-year-old man left brain damaged as a baby...</td>\n",
       "      <td>25-year-old was left brain damaged after docto...</td>\n",
       "      <td>61</td>\n",
       "      <td>A man brain damaged as a baby after doctors f...</td>\n",
       "      <td>A 25-year-old man with brain damage sustained ...</td>\n",
       "      <td>A 25-year-old man, left brain damaged as a bab...</td>\n",
       "      <td>A 25-year-old man has won a £7.3 million compe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>The days of filling your car with petrol may b...</td>\n",
       "      <td>Virginia Polytechnic Institute and State Unive...</td>\n",
       "      <td>59</td>\n",
       "      <td>US scientists have developed a method using p...</td>\n",
       "      <td>US researchers have developed a method to effi...</td>\n",
       "      <td>US scientists have boosted efficiency in produ...</td>\n",
       "      <td>US scientists have developed a method to effic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>A former air stewardess who was struck down by...</td>\n",
       "      <td>Gemma Flanagan, 31, from Liverpool, was hit by...</td>\n",
       "      <td>50</td>\n",
       "      <td>Former air stewardess Gemma Flanagan made her...</td>\n",
       "      <td>Gemma Flanagan, a former air stewardess, was p...</td>\n",
       "      <td>Gemma Flanagan, 31, a former British Airways s...</td>\n",
       "      <td>Gemma Flanagan, a former air stewardess, will ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              article  \\\n",
       "0   Model-turned-jihadist Sharky Jama has reported...   \n",
       "1   A New York teen who lost everything in Hurrica...   \n",
       "2   Media personality Miranda Devine has apologise...   \n",
       "3   A New York man was indicted Wednesday on multi...   \n",
       "4   Magnificent carpets of wild bluebells have spr...   \n",
       "..                                                ...   \n",
       "95  An Ohio couple have been found dead in an appa...   \n",
       "96  Shabana Bibi, died in hospital on Saturday Apr...   \n",
       "97  A 25-year-old man left brain damaged as a baby...   \n",
       "98  The days of filling your car with petrol may b...   \n",
       "99  A former air stewardess who was struck down by...   \n",
       "\n",
       "                                           highlights  count  \\\n",
       "0   Melbourne model Sharky Jama has reportedly bee...     55   \n",
       "1   New York teen Daria Rose lost everything in Hu...     57   \n",
       "2   After scoring a try on Friday night, David Poc...     51   \n",
       "3   Edward Nudel, 41, was indicted Wednesday on mu...     46   \n",
       "4   Photographs taken in Micheldever Woods, Hampsh...     59   \n",
       "..                                                ...    ...   \n",
       "95  The couple are in their 50s and from Cleveland...     43   \n",
       "96  Shabana Bibi, 25, died after she suffered burn...     57   \n",
       "97  25-year-old was left brain damaged after docto...     61   \n",
       "98  Virginia Polytechnic Institute and State Unive...     59   \n",
       "99  Gemma Flanagan, 31, from Liverpool, was hit by...     50   \n",
       "\n",
       "                                        nemotron-mini  \\\n",
       "0    Sharky Jama, a model turned jihadist from Mel...   \n",
       "1    Daria Rose, an 18-year-old New York teen who ...   \n",
       "2    Miranda Devine apologized for calling David P...   \n",
       "3    New York man indicted for strangling relative...   \n",
       "4    Stunning carpets of wild bluebells have bloss...   \n",
       "..                                                ...   \n",
       "95   An Ohio couple died in an apparent murder-sui...   \n",
       "96   Shabana Bibi was found dead after suffering b...   \n",
       "97   A man brain damaged as a baby after doctors f...   \n",
       "98   US scientists have developed a method using p...   \n",
       "99   Former air stewardess Gemma Flanagan made her...   \n",
       "\n",
       "                                            gemma2:9b  \\\n",
       "0   Sharky Jama, a former Melbourne model, was rep...   \n",
       "1   Daria Rose, an 18-year-old from Hempstead, New...   \n",
       "2   Miranda Devine called rugby player David Pococ...   \n",
       "3   Edward Nudel strangled his relative's 2-year-o...   \n",
       "4   Wild bluebells are blooming weeks ahead of sch...   \n",
       "..                                                ...   \n",
       "95  A couple from Cleveland, Ohio, were found dead...   \n",
       "96  Shabana Bibi, 25, died from burns covering 80%...   \n",
       "97  A 25-year-old man with brain damage sustained ...   \n",
       "98  US researchers have developed a method to effi...   \n",
       "99  Gemma Flanagan, a former air stewardess, was p...   \n",
       "\n",
       "                                             nemotron  \\\n",
       "0   Melbourne model Sharky Jama, who joined Islami...   \n",
       "1   Daria Rose, 18, accepted into all 7 Ivy League...   \n",
       "2   Media personality Miranda Devine apologized fo...   \n",
       "3   Edward Nudel, 41, indicted for strangling rela...   \n",
       "4   UK's balmy spring weather brings early bloom t...   \n",
       "..                                                ...   \n",
       "95  Ohio couple (both in their 50s from Cleveland)...   \n",
       "96  Shabana Bibi, 25, died from 80% burns after al...   \n",
       "97  A 25-year-old man, left brain damaged as a bab...   \n",
       "98  US scientists have boosted efficiency in produ...   \n",
       "99  Gemma Flanagan, 31, a former British Airways s...   \n",
       "\n",
       "                                           gemma2:27b  \n",
       "0   Sharky Jama, a former Melbourne model, has rep...  \n",
       "1   Daria Rose, an 18-year-old from Hempstead, New...  \n",
       "2   Miranda Devine apologized for calling rugby pl...  \n",
       "3   Edward Nudel, 41, was indicted for strangling ...  \n",
       "4   Wild bluebells are blooming weeks early in Eng...  \n",
       "..                                                ...  \n",
       "95  An Ohio couple in their 50s were found dead in...  \n",
       "96  Shabana Bibi, 25, died from burns after allege...  \n",
       "97  A 25-year-old man has won a £7.3 million compe...  \n",
       "98  US scientists have developed a method to effic...  \n",
       "99  Gemma Flanagan, a former air stewardess, will ...  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_quotes(column):\n",
    "    return column.apply(lambda x: x[1:-1] if isinstance(x, str) and x.startswith('\"') and x.endswith('\"') else x)\n",
    "data['nemotron'] = remove_quotes(data['nemotron'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "dcd0743b-dd39-4861-b0ed-3c81b9d87de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['article', 'highlights', 'count', 'nemotron-mini', 'gemma2:9b',\n",
       "       'nemotron', 'gemma2:27b'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data.to_csv('small_big_llms2.csv')\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eac5a1-f940-4d5f-ba18-aacd0c3a0da9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba57f9d-91b4-42fe-b575-d7a4c8a81acd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66888577-2f4e-4896-ae7e-0d1314c70ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0e9c0f-5577-40f0-8c59-46b5abc7dcd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b72333d8-571e-4814-bade-def384269a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in ./sp/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Collecting joblib (from nltk)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./sp/lib/python3.12/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in ./sp/lib/python3.12/site-packages (from nltk) (4.66.6)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m134.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m129.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: joblib, nltk\n",
      "Successfully installed joblib-1.4.2 nltk-3.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b14d4b43-ac45-4dbd-a70d-c76563c47b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/chatbot/nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to /home/chatbot/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "12228999-a3bc-442e-85ac-7e3f18258e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>nemotron-mini</th>\n",
       "      <th>gemma2:9b</th>\n",
       "      <th>nemotron</th>\n",
       "      <th>gemma2:27b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model-turned-jihadist Sharky Jama has reported...</td>\n",
       "      <td>Melbourne model Sharky Jama has reportedly bee...</td>\n",
       "      <td>Sharky Jama, a model turned jihadist from Mel...</td>\n",
       "      <td>Sharky Jama, a former Melbourne model, was rep...</td>\n",
       "      <td>Melbourne model Sharky Jama, who joined Islami...</td>\n",
       "      <td>Sharky Jama, a former Melbourne model, has rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A New York teen who lost everything in Hurrica...</td>\n",
       "      <td>New York teen Daria Rose lost everything in Hu...</td>\n",
       "      <td>Daria Rose, an 18-year-old New York teen who ...</td>\n",
       "      <td>Daria Rose, an 18-year-old from Hempstead, New...</td>\n",
       "      <td>Daria Rose, 18, accepted into all 7 Ivy League...</td>\n",
       "      <td>Daria Rose, an 18-year-old from Hempstead, New...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Media personality Miranda Devine has apologise...</td>\n",
       "      <td>After scoring a try on Friday night, David Poc...</td>\n",
       "      <td>Miranda Devine apologized for calling David P...</td>\n",
       "      <td>Miranda Devine called rugby player David Pococ...</td>\n",
       "      <td>Media personality Miranda Devine apologized fo...</td>\n",
       "      <td>Miranda Devine apologized for calling rugby pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A New York man was indicted Wednesday on multi...</td>\n",
       "      <td>Edward Nudel, 41, was indicted Wednesday on mu...</td>\n",
       "      <td>New York man indicted for strangling relative...</td>\n",
       "      <td>Edward Nudel strangled his relative's 2-year-o...</td>\n",
       "      <td>Edward Nudel, 41, indicted for strangling rela...</td>\n",
       "      <td>Edward Nudel, 41, was indicted for strangling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Magnificent carpets of wild bluebells have spr...</td>\n",
       "      <td>Photographs taken in Micheldever Woods, Hampsh...</td>\n",
       "      <td>Stunning carpets of wild bluebells have bloss...</td>\n",
       "      <td>Wild bluebells are blooming weeks ahead of sch...</td>\n",
       "      <td>UK's balmy spring weather brings early bloom t...</td>\n",
       "      <td>Wild bluebells are blooming weeks early in Eng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>An Ohio couple have been found dead in an appa...</td>\n",
       "      <td>The couple are in their 50s and from Cleveland...</td>\n",
       "      <td>An Ohio couple died in an apparent murder-sui...</td>\n",
       "      <td>A couple from Cleveland, Ohio, were found dead...</td>\n",
       "      <td>Ohio couple (both in their 50s from Cleveland)...</td>\n",
       "      <td>An Ohio couple in their 50s were found dead in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Shabana Bibi, died in hospital on Saturday Apr...</td>\n",
       "      <td>Shabana Bibi, 25, died after she suffered burn...</td>\n",
       "      <td>Shabana Bibi was found dead after suffering b...</td>\n",
       "      <td>Shabana Bibi, 25, died from burns covering 80%...</td>\n",
       "      <td>Shabana Bibi, 25, died from 80% burns after al...</td>\n",
       "      <td>Shabana Bibi, 25, died from burns after allege...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>A 25-year-old man left brain damaged as a baby...</td>\n",
       "      <td>25-year-old was left brain damaged after docto...</td>\n",
       "      <td>A man brain damaged as a baby after doctors f...</td>\n",
       "      <td>A 25-year-old man with brain damage sustained ...</td>\n",
       "      <td>A 25-year-old man, left brain damaged as a bab...</td>\n",
       "      <td>A 25-year-old man has won a £7.3 million compe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>The days of filling your car with petrol may b...</td>\n",
       "      <td>Virginia Polytechnic Institute and State Unive...</td>\n",
       "      <td>US scientists have developed a method using p...</td>\n",
       "      <td>US researchers have developed a method to effi...</td>\n",
       "      <td>US scientists have boosted efficiency in produ...</td>\n",
       "      <td>US scientists have developed a method to effic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>A former air stewardess who was struck down by...</td>\n",
       "      <td>Gemma Flanagan, 31, from Liverpool, was hit by...</td>\n",
       "      <td>Former air stewardess Gemma Flanagan made her...</td>\n",
       "      <td>Gemma Flanagan, a former air stewardess, was p...</td>\n",
       "      <td>Gemma Flanagan, 31, a former British Airways s...</td>\n",
       "      <td>Gemma Flanagan, a former air stewardess, will ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              article  \\\n",
       "0   Model-turned-jihadist Sharky Jama has reported...   \n",
       "1   A New York teen who lost everything in Hurrica...   \n",
       "2   Media personality Miranda Devine has apologise...   \n",
       "3   A New York man was indicted Wednesday on multi...   \n",
       "4   Magnificent carpets of wild bluebells have spr...   \n",
       "..                                                ...   \n",
       "95  An Ohio couple have been found dead in an appa...   \n",
       "96  Shabana Bibi, died in hospital on Saturday Apr...   \n",
       "97  A 25-year-old man left brain damaged as a baby...   \n",
       "98  The days of filling your car with petrol may b...   \n",
       "99  A former air stewardess who was struck down by...   \n",
       "\n",
       "                                           highlights  \\\n",
       "0   Melbourne model Sharky Jama has reportedly bee...   \n",
       "1   New York teen Daria Rose lost everything in Hu...   \n",
       "2   After scoring a try on Friday night, David Poc...   \n",
       "3   Edward Nudel, 41, was indicted Wednesday on mu...   \n",
       "4   Photographs taken in Micheldever Woods, Hampsh...   \n",
       "..                                                ...   \n",
       "95  The couple are in their 50s and from Cleveland...   \n",
       "96  Shabana Bibi, 25, died after she suffered burn...   \n",
       "97  25-year-old was left brain damaged after docto...   \n",
       "98  Virginia Polytechnic Institute and State Unive...   \n",
       "99  Gemma Flanagan, 31, from Liverpool, was hit by...   \n",
       "\n",
       "                                        nemotron-mini  \\\n",
       "0    Sharky Jama, a model turned jihadist from Mel...   \n",
       "1    Daria Rose, an 18-year-old New York teen who ...   \n",
       "2    Miranda Devine apologized for calling David P...   \n",
       "3    New York man indicted for strangling relative...   \n",
       "4    Stunning carpets of wild bluebells have bloss...   \n",
       "..                                                ...   \n",
       "95   An Ohio couple died in an apparent murder-sui...   \n",
       "96   Shabana Bibi was found dead after suffering b...   \n",
       "97   A man brain damaged as a baby after doctors f...   \n",
       "98   US scientists have developed a method using p...   \n",
       "99   Former air stewardess Gemma Flanagan made her...   \n",
       "\n",
       "                                            gemma2:9b  \\\n",
       "0   Sharky Jama, a former Melbourne model, was rep...   \n",
       "1   Daria Rose, an 18-year-old from Hempstead, New...   \n",
       "2   Miranda Devine called rugby player David Pococ...   \n",
       "3   Edward Nudel strangled his relative's 2-year-o...   \n",
       "4   Wild bluebells are blooming weeks ahead of sch...   \n",
       "..                                                ...   \n",
       "95  A couple from Cleveland, Ohio, were found dead...   \n",
       "96  Shabana Bibi, 25, died from burns covering 80%...   \n",
       "97  A 25-year-old man with brain damage sustained ...   \n",
       "98  US researchers have developed a method to effi...   \n",
       "99  Gemma Flanagan, a former air stewardess, was p...   \n",
       "\n",
       "                                             nemotron  \\\n",
       "0   Melbourne model Sharky Jama, who joined Islami...   \n",
       "1   Daria Rose, 18, accepted into all 7 Ivy League...   \n",
       "2   Media personality Miranda Devine apologized fo...   \n",
       "3   Edward Nudel, 41, indicted for strangling rela...   \n",
       "4   UK's balmy spring weather brings early bloom t...   \n",
       "..                                                ...   \n",
       "95  Ohio couple (both in their 50s from Cleveland)...   \n",
       "96  Shabana Bibi, 25, died from 80% burns after al...   \n",
       "97  A 25-year-old man, left brain damaged as a bab...   \n",
       "98  US scientists have boosted efficiency in produ...   \n",
       "99  Gemma Flanagan, 31, a former British Airways s...   \n",
       "\n",
       "                                           gemma2:27b  \n",
       "0   Sharky Jama, a former Melbourne model, has rep...  \n",
       "1   Daria Rose, an 18-year-old from Hempstead, New...  \n",
       "2   Miranda Devine apologized for calling rugby pl...  \n",
       "3   Edward Nudel, 41, was indicted for strangling ...  \n",
       "4   Wild bluebells are blooming weeks early in Eng...  \n",
       "..                                                ...  \n",
       "95  An Ohio couple in their 50s were found dead in...  \n",
       "96  Shabana Bibi, 25, died from burns after allege...  \n",
       "97  A 25-year-old man has won a £7.3 million compe...  \n",
       "98  US scientists have developed a method to effic...  \n",
       "99  Gemma Flanagan, a former air stewardess, will ...  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data\n",
    "df = df.drop(columns=['count'],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f10acd6e-e30b-4e42-bf17-110f426f512b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/chatbot/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "fec7d704-a231-4234-9038-de0ec8ec8f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating scores for nemotron-mini...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  1%|▍                                          | 1/100 [00:01<01:45,  1.07s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  2%|▊                                          | 2/100 [00:01<01:28,  1.11it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  3%|█▎                                         | 3/100 [00:02<01:21,  1.19it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  4%|█▋                                         | 4/100 [00:03<01:18,  1.23it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  5%|██▏                                        | 5/100 [00:04<01:15,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  6%|██▌                                        | 6/100 [00:04<01:14,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  7%|███                                        | 7/100 [00:05<01:12,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  8%|███▍                                       | 8/100 [00:06<01:12,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  9%|███▊                                       | 9/100 [00:07<01:22,  1.11it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 10%|████▏                                     | 10/100 [00:08<01:17,  1.16it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 11%|████▌                                     | 11/100 [00:09<01:14,  1.20it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 12%|█████                                     | 12/100 [00:09<01:11,  1.23it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 13%|█████▍                                    | 13/100 [00:10<01:10,  1.24it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 14%|█████▉                                    | 14/100 [00:11<01:09,  1.24it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 15%|██████▎                                   | 15/100 [00:12<01:07,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 16%|██████▋                                   | 16/100 [00:13<01:06,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 17%|███████▏                                  | 17/100 [00:13<01:05,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 18%|███████▌                                  | 18/100 [00:14<01:04,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 19%|███████▉                                  | 19/100 [00:15<01:03,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 20%|████████▍                                 | 20/100 [00:16<01:02,  1.27it/s]/home/chatbot/Desktop/sp_data/sp/lib/python3.12/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 21%|████████▊                                 | 21/100 [00:17<01:01,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 22%|█████████▏                                | 22/100 [00:17<01:00,  1.29it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 23%|█████████▋                                | 23/100 [00:18<00:59,  1.29it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 24%|██████████                                | 24/100 [00:19<00:58,  1.29it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 25%|██████████▌                               | 25/100 [00:20<00:58,  1.29it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 26%|██████████▉                               | 26/100 [00:20<00:58,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 27%|███████████▎                              | 27/100 [00:21<00:57,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 28%|███████████▊                              | 28/100 [00:22<00:56,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 29%|████████████▏                             | 29/100 [00:23<00:55,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 30%|████████████▌                             | 30/100 [00:24<01:00,  1.16it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 31%|█████████████                             | 31/100 [00:25<00:57,  1.20it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 32%|█████████████▍                            | 32/100 [00:25<00:55,  1.23it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 33%|█████████████▊                            | 33/100 [00:26<00:53,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 34%|██████████████▎                           | 34/100 [00:27<00:52,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 35%|██████████████▋                           | 35/100 [00:28<00:51,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 36%|███████████████                           | 36/100 [00:28<00:50,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 37%|███████████████▌                          | 37/100 [00:29<00:49,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 38%|███████████████▉                          | 38/100 [00:30<00:48,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 39%|████████████████▍                         | 39/100 [00:31<00:48,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 40%|████████████████▊                         | 40/100 [00:32<00:53,  1.12it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 41%|█████████████████▏                        | 41/100 [00:33<00:50,  1.16it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 42%|█████████████████▋                        | 42/100 [00:34<00:48,  1.20it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 43%|██████████████████                        | 43/100 [00:34<00:46,  1.22it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 44%|██████████████████▍                       | 44/100 [00:35<00:45,  1.24it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 45%|██████████████████▉                       | 45/100 [00:36<00:44,  1.24it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 46%|███████████████████▎                      | 46/100 [00:37<00:43,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 47%|███████████████████▋                      | 47/100 [00:37<00:42,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 48%|████████████████████▏                     | 48/100 [00:38<00:41,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 49%|████████████████████▌                     | 49/100 [00:39<00:41,  1.24it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 50%|█████████████████████                     | 50/100 [00:40<00:40,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 51%|█████████████████████▍                    | 51/100 [00:41<00:39,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 52%|█████████████████████▊                    | 52/100 [00:41<00:37,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 53%|██████████████████████▎                   | 53/100 [00:42<00:37,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 54%|██████████████████████▋                   | 54/100 [00:43<00:36,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 55%|███████████████████████                   | 55/100 [00:44<00:35,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 56%|███████████████████████▌                  | 56/100 [00:45<00:34,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 57%|███████████████████████▉                  | 57/100 [00:45<00:34,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 58%|████████████████████████▎                 | 58/100 [00:46<00:33,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 59%|████████████████████████▊                 | 59/100 [00:47<00:32,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 60%|█████████████████████████▏                | 60/100 [00:48<00:31,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 61%|█████████████████████████▌                | 61/100 [00:49<00:30,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 62%|██████████████████████████                | 62/100 [00:49<00:29,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 63%|██████████████████████████▍               | 63/100 [00:50<00:28,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 64%|██████████████████████████▉               | 64/100 [00:51<00:28,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 65%|███████████████████████████▎              | 65/100 [00:52<00:27,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 66%|███████████████████████████▋              | 66/100 [00:52<00:26,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 67%|████████████████████████████▏             | 67/100 [00:53<00:25,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 68%|████████████████████████████▌             | 68/100 [00:54<00:25,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 69%|████████████████████████████▉             | 69/100 [00:55<00:25,  1.22it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 70%|█████████████████████████████▍            | 70/100 [00:56<00:24,  1.24it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 71%|█████████████████████████████▊            | 71/100 [00:56<00:23,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 72%|██████████████████████████████▏           | 72/100 [00:57<00:22,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 73%|██████████████████████████████▋           | 73/100 [00:58<00:22,  1.22it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 74%|███████████████████████████████           | 74/100 [00:59<00:23,  1.10it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 75%|███████████████████████████████▌          | 75/100 [01:00<00:21,  1.15it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 76%|███████████████████████████████▉          | 76/100 [01:01<00:20,  1.19it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 77%|████████████████████████████████▎         | 77/100 [01:02<00:20,  1.10it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 78%|████████████████████████████████▊         | 78/100 [01:03<00:19,  1.15it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 79%|█████████████████████████████████▏        | 79/100 [01:04<00:19,  1.08it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 80%|█████████████████████████████████▌        | 80/100 [01:04<00:17,  1.13it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 81%|██████████████████████████████████        | 81/100 [01:05<00:16,  1.18it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 82%|██████████████████████████████████▍       | 82/100 [01:06<00:16,  1.09it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 83%|██████████████████████████████████▊       | 83/100 [01:07<00:14,  1.15it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 84%|███████████████████████████████████▎      | 84/100 [01:08<00:14,  1.08it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 85%|███████████████████████████████████▋      | 85/100 [01:09<00:13,  1.13it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 86%|████████████████████████████████████      | 86/100 [01:10<00:11,  1.18it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 87%|████████████████████████████████████▌     | 87/100 [01:10<00:10,  1.21it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 88%|████████████████████████████████████▉     | 88/100 [01:11<00:09,  1.23it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 89%|█████████████████████████████████████▍    | 89/100 [01:12<00:09,  1.20it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 90%|█████████████████████████████████████▊    | 90/100 [01:13<00:09,  1.10it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 91%|██████████████████████████████████████▏   | 91/100 [01:14<00:07,  1.15it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 92%|██████████████████████████████████████▋   | 92/100 [01:15<00:06,  1.16it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 93%|███████████████████████████████████████   | 93/100 [01:16<00:05,  1.19it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 94%|███████████████████████████████████████▍  | 94/100 [01:16<00:04,  1.21it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 95%|███████████████████████████████████████▉  | 95/100 [01:17<00:04,  1.23it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 96%|████████████████████████████████████████▎ | 96/100 [01:18<00:03,  1.24it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 97%|████████████████████████████████████████▋ | 97/100 [01:19<00:02,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 98%|█████████████████████████████████████████▏| 98/100 [01:20<00:01,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 99%|█████████████████████████████████████████▌| 99/100 [01:20<00:00,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|█████████████████████████████████████████| 100/100 [01:21<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating scores for gemma2:9b...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  1%|▍                                          | 1/100 [00:00<01:18,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  2%|▊                                          | 2/100 [00:01<01:16,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  3%|█▎                                         | 3/100 [00:02<01:16,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  4%|█▋                                         | 4/100 [00:03<01:15,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  5%|██▏                                        | 5/100 [00:03<01:14,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  6%|██▌                                        | 6/100 [00:04<01:13,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  7%|███                                        | 7/100 [00:05<01:24,  1.11it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  8%|███▍                                       | 8/100 [00:06<01:24,  1.09it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  9%|███▊                                       | 9/100 [00:07<01:19,  1.14it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 10%|████▏                                     | 10/100 [00:08<01:16,  1.18it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 11%|████▌                                     | 11/100 [00:09<01:13,  1.20it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 12%|█████                                     | 12/100 [00:09<01:11,  1.22it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 13%|█████▍                                    | 13/100 [00:10<01:10,  1.24it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 14%|█████▉                                    | 14/100 [00:11<01:10,  1.22it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 15%|██████▎                                   | 15/100 [00:12<01:08,  1.24it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 16%|██████▋                                   | 16/100 [00:13<01:07,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 17%|███████▏                                  | 17/100 [00:13<01:06,  1.24it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 18%|███████▌                                  | 18/100 [00:14<01:05,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 19%|███████▉                                  | 19/100 [00:15<01:04,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 20%|████████▍                                 | 20/100 [00:16<01:03,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 21%|████████▊                                 | 21/100 [00:17<01:02,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 22%|█████████▏                                | 22/100 [00:18<01:04,  1.22it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 23%|█████████▋                                | 23/100 [00:18<01:03,  1.22it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 24%|██████████                                | 24/100 [00:19<01:01,  1.24it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 25%|██████████▌                               | 25/100 [00:20<01:00,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 26%|██████████▉                               | 26/100 [00:21<00:59,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 27%|███████████▎                              | 27/100 [00:22<00:59,  1.23it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 28%|███████████▊                              | 28/100 [00:22<00:57,  1.24it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 29%|████████████▏                             | 29/100 [00:23<00:56,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 30%|████████████▌                             | 30/100 [00:24<00:55,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 31%|█████████████                             | 31/100 [00:25<00:55,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 32%|█████████████▍                            | 32/100 [00:26<00:54,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 33%|█████████████▊                            | 33/100 [00:26<00:53,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 34%|██████████████▎                           | 34/100 [00:27<00:52,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 35%|██████████████▋                           | 35/100 [00:28<00:51,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 36%|███████████████                           | 36/100 [00:29<00:50,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 37%|███████████████▌                          | 37/100 [00:30<00:50,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 38%|███████████████▉                          | 38/100 [00:30<00:50,  1.23it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 39%|████████████████▍                         | 39/100 [00:31<00:49,  1.24it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 40%|████████████████▊                         | 40/100 [00:32<00:47,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 41%|█████████████████▏                        | 41/100 [00:33<00:46,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 42%|█████████████████▋                        | 42/100 [00:34<00:51,  1.12it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 43%|██████████████████                        | 43/100 [00:35<00:48,  1.16it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 44%|██████████████████▍                       | 44/100 [00:35<00:47,  1.17it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 45%|██████████████████▉                       | 45/100 [00:36<00:45,  1.20it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 46%|███████████████████▎                      | 46/100 [00:37<00:44,  1.22it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 47%|███████████████████▋                      | 47/100 [00:38<00:42,  1.23it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 48%|████████████████████▏                     | 48/100 [00:39<00:41,  1.24it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 49%|████████████████████▌                     | 49/100 [00:39<00:41,  1.23it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 50%|█████████████████████                     | 50/100 [00:40<00:41,  1.20it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 51%|█████████████████████▍                    | 51/100 [00:41<00:39,  1.23it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 52%|█████████████████████▊                    | 52/100 [00:42<00:38,  1.24it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 53%|██████████████████████▎                   | 53/100 [00:43<00:37,  1.24it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 54%|██████████████████████▋                   | 54/100 [00:43<00:36,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 55%|███████████████████████                   | 55/100 [00:44<00:35,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 56%|███████████████████████▌                  | 56/100 [00:45<00:34,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 57%|███████████████████████▉                  | 57/100 [00:46<00:34,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 58%|████████████████████████▎                 | 58/100 [00:47<00:33,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 59%|████████████████████████▊                 | 59/100 [00:47<00:32,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 60%|█████████████████████████▏                | 60/100 [00:48<00:31,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 61%|█████████████████████████▌                | 61/100 [00:49<00:30,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 62%|██████████████████████████                | 62/100 [00:50<00:30,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 63%|██████████████████████████▍               | 63/100 [00:51<00:29,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 64%|██████████████████████████▉               | 64/100 [00:51<00:28,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 65%|███████████████████████████▎              | 65/100 [00:52<00:30,  1.16it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 66%|███████████████████████████▋              | 66/100 [00:53<00:28,  1.19it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 67%|████████████████████████████▏             | 67/100 [00:54<00:29,  1.12it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 68%|████████████████████████████▌             | 68/100 [00:55<00:27,  1.16it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 69%|████████████████████████████▉             | 69/100 [00:56<00:26,  1.19it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 70%|█████████████████████████████▍            | 70/100 [00:57<00:24,  1.22it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 71%|█████████████████████████████▊            | 71/100 [00:58<00:26,  1.11it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 72%|██████████████████████████████▏           | 72/100 [00:58<00:24,  1.14it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 73%|██████████████████████████████▋           | 73/100 [00:59<00:23,  1.16it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 74%|███████████████████████████████           | 74/100 [01:00<00:22,  1.17it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 75%|███████████████████████████████▌          | 75/100 [01:01<00:20,  1.19it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 76%|███████████████████████████████▉          | 76/100 [01:02<00:19,  1.20it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 77%|████████████████████████████████▎         | 77/100 [01:03<00:18,  1.22it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 78%|████████████████████████████████▊         | 78/100 [01:04<00:20,  1.09it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 79%|█████████████████████████████████▏        | 79/100 [01:04<00:18,  1.14it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 80%|█████████████████████████████████▌        | 80/100 [01:05<00:16,  1.18it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 81%|██████████████████████████████████        | 81/100 [01:06<00:16,  1.18it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 82%|██████████████████████████████████▍       | 82/100 [01:07<00:14,  1.21it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 83%|██████████████████████████████████▊       | 83/100 [01:08<00:13,  1.23it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 84%|███████████████████████████████████▎      | 84/100 [01:08<00:12,  1.24it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 85%|███████████████████████████████████▋      | 85/100 [01:09<00:12,  1.23it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 86%|████████████████████████████████████      | 86/100 [01:10<00:11,  1.23it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 87%|████████████████████████████████████▌     | 87/100 [01:11<00:10,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 88%|████████████████████████████████████▉     | 88/100 [01:12<00:09,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 89%|█████████████████████████████████████▍    | 89/100 [01:12<00:08,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 90%|█████████████████████████████████████▊    | 90/100 [01:13<00:07,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 91%|██████████████████████████████████████▏   | 91/100 [01:14<00:07,  1.14it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 92%|██████████████████████████████████████▋   | 92/100 [01:15<00:06,  1.16it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 93%|███████████████████████████████████████   | 93/100 [01:16<00:05,  1.19it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 94%|███████████████████████████████████████▍  | 94/100 [01:17<00:05,  1.20it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 95%|███████████████████████████████████████▉  | 95/100 [01:17<00:04,  1.23it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 96%|████████████████████████████████████████▎ | 96/100 [01:18<00:03,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 97%|████████████████████████████████████████▋ | 97/100 [01:19<00:02,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 98%|█████████████████████████████████████████▏| 98/100 [01:20<00:01,  1.22it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 99%|█████████████████████████████████████████▌| 99/100 [01:21<00:00,  1.24it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|█████████████████████████████████████████| 100/100 [01:21<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating scores for nemotron...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  1%|▍                                          | 1/100 [00:01<01:41,  1.03s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  2%|▊                                          | 2/100 [00:01<01:26,  1.14it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  3%|█▎                                         | 3/100 [00:02<01:20,  1.20it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  4%|█▋                                         | 4/100 [00:03<01:17,  1.23it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  5%|██▏                                        | 5/100 [00:04<01:16,  1.24it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  6%|██▌                                        | 6/100 [00:04<01:14,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  7%|███                                        | 7/100 [00:05<01:14,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  8%|███▍                                       | 8/100 [00:06<01:14,  1.24it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  9%|███▊                                       | 9/100 [00:07<01:13,  1.24it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 10%|████▏                                     | 10/100 [00:08<01:11,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 11%|████▌                                     | 11/100 [00:09<01:17,  1.15it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 12%|█████                                     | 12/100 [00:09<01:14,  1.19it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 13%|█████▍                                    | 13/100 [00:10<01:12,  1.21it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 14%|█████▉                                    | 14/100 [00:11<01:19,  1.08it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 15%|██████▎                                   | 15/100 [00:12<01:14,  1.14it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 16%|██████▋                                   | 16/100 [00:13<01:11,  1.18it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 17%|███████▏                                  | 17/100 [00:14<01:08,  1.21it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 18%|███████▌                                  | 18/100 [00:15<01:06,  1.22it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 19%|███████▉                                  | 19/100 [00:15<01:05,  1.23it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 20%|████████▍                                 | 20/100 [00:16<01:04,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 21%|████████▊                                 | 21/100 [00:17<01:02,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 22%|█████████▏                                | 22/100 [00:18<01:01,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 23%|█████████▋                                | 23/100 [00:18<01:00,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 24%|██████████                                | 24/100 [00:19<01:01,  1.23it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 25%|██████████▌                               | 25/100 [00:20<01:00,  1.24it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 26%|██████████▉                               | 26/100 [00:21<01:06,  1.12it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 27%|███████████▎                              | 27/100 [00:22<01:02,  1.17it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 28%|███████████▊                              | 28/100 [00:23<00:59,  1.20it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 29%|████████████▏                             | 29/100 [00:24<00:57,  1.23it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 30%|████████████▌                             | 30/100 [00:24<00:56,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 31%|█████████████                             | 31/100 [00:25<00:54,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 32%|█████████████▍                            | 32/100 [00:26<00:54,  1.24it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 33%|█████████████▊                            | 33/100 [00:27<00:53,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 34%|██████████████▎                           | 34/100 [00:27<00:52,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 35%|██████████████▋                           | 35/100 [00:28<00:51,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 36%|███████████████                           | 36/100 [00:29<00:50,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 37%|███████████████▌                          | 37/100 [00:30<00:49,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 38%|███████████████▉                          | 38/100 [00:31<00:49,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 39%|████████████████▍                         | 39/100 [00:31<00:48,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 40%|████████████████▊                         | 40/100 [00:32<00:48,  1.24it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 41%|█████████████████▏                        | 41/100 [00:33<00:46,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 42%|█████████████████▋                        | 42/100 [00:34<00:45,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 43%|██████████████████                        | 43/100 [00:35<00:44,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 44%|██████████████████▍                       | 44/100 [00:35<00:43,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 45%|██████████████████▉                       | 45/100 [00:36<00:43,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 46%|███████████████████▎                      | 46/100 [00:37<00:42,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 47%|███████████████████▋                      | 47/100 [00:38<00:41,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 48%|████████████████████▏                     | 48/100 [00:39<00:44,  1.16it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 49%|████████████████████▌                     | 49/100 [00:40<00:42,  1.20it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 50%|█████████████████████                     | 50/100 [00:40<00:40,  1.23it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 51%|█████████████████████▍                    | 51/100 [00:41<00:39,  1.23it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 52%|█████████████████████▊                    | 52/100 [00:42<00:43,  1.09it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 53%|██████████████████████▎                   | 53/100 [00:43<00:41,  1.14it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 54%|██████████████████████▋                   | 54/100 [00:44<00:38,  1.18it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 55%|███████████████████████                   | 55/100 [00:45<00:38,  1.18it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 56%|███████████████████████▌                  | 56/100 [00:45<00:36,  1.20it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 57%|███████████████████████▉                  | 57/100 [00:46<00:35,  1.22it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 58%|████████████████████████▎                 | 58/100 [00:47<00:33,  1.24it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 59%|████████████████████████▊                 | 59/100 [00:48<00:32,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 60%|█████████████████████████▏                | 60/100 [00:49<00:35,  1.13it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 61%|█████████████████████████▌                | 61/100 [00:50<00:34,  1.14it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 62%|██████████████████████████                | 62/100 [00:51<00:32,  1.18it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 63%|██████████████████████████▍               | 63/100 [00:51<00:30,  1.21it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 64%|██████████████████████████▉               | 64/100 [00:52<00:29,  1.23it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 65%|███████████████████████████▎              | 65/100 [00:53<00:28,  1.23it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 66%|███████████████████████████▋              | 66/100 [00:54<00:27,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 67%|████████████████████████████▏             | 67/100 [00:54<00:26,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 68%|████████████████████████████▌             | 68/100 [00:55<00:25,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 69%|████████████████████████████▉             | 69/100 [00:56<00:24,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 70%|█████████████████████████████▍            | 70/100 [00:57<00:23,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 71%|█████████████████████████████▊            | 71/100 [00:58<00:23,  1.23it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 72%|██████████████████████████████▏           | 72/100 [00:58<00:22,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 73%|██████████████████████████████▋           | 73/100 [00:59<00:21,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 74%|███████████████████████████████           | 74/100 [01:00<00:20,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 75%|███████████████████████████████▌          | 75/100 [01:01<00:19,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 76%|███████████████████████████████▉          | 76/100 [01:02<00:19,  1.24it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 77%|████████████████████████████████▎         | 77/100 [01:02<00:18,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 78%|████████████████████████████████▊         | 78/100 [01:03<00:17,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 79%|█████████████████████████████████▏        | 79/100 [01:04<00:16,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 80%|█████████████████████████████████▌        | 80/100 [01:05<00:15,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 81%|██████████████████████████████████        | 81/100 [01:05<00:14,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 82%|██████████████████████████████████▍       | 82/100 [01:06<00:14,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 83%|██████████████████████████████████▊       | 83/100 [01:07<00:13,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 84%|███████████████████████████████████▎      | 84/100 [01:08<00:12,  1.29it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 85%|███████████████████████████████████▋      | 85/100 [01:09<00:11,  1.29it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 86%|████████████████████████████████████      | 86/100 [01:09<00:10,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 87%|████████████████████████████████████▌     | 87/100 [01:10<00:10,  1.29it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 88%|████████████████████████████████████▉     | 88/100 [01:11<00:09,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 89%|█████████████████████████████████████▍    | 89/100 [01:12<00:08,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 90%|█████████████████████████████████████▊    | 90/100 [01:13<00:08,  1.12it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 91%|██████████████████████████████████████▏   | 91/100 [01:14<00:07,  1.16it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 92%|██████████████████████████████████████▋   | 92/100 [01:14<00:06,  1.20it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 93%|███████████████████████████████████████   | 93/100 [01:15<00:05,  1.22it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 94%|███████████████████████████████████████▍  | 94/100 [01:16<00:04,  1.23it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 95%|███████████████████████████████████████▉  | 95/100 [01:17<00:04,  1.24it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 96%|████████████████████████████████████████▎ | 96/100 [01:18<00:03,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 97%|████████████████████████████████████████▋ | 97/100 [01:18<00:02,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 98%|█████████████████████████████████████████▏| 98/100 [01:19<00:01,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 99%|█████████████████████████████████████████▌| 99/100 [01:20<00:00,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|█████████████████████████████████████████| 100/100 [01:21<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating scores for gemma2:27b...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  1%|▍                                          | 1/100 [00:00<01:16,  1.29it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  2%|▊                                          | 2/100 [00:01<01:16,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  3%|█▎                                         | 3/100 [00:02<01:16,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  4%|█▋                                         | 4/100 [00:03<01:15,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  5%|██▏                                        | 5/100 [00:03<01:14,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  6%|██▌                                        | 6/100 [00:04<01:13,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  7%|███                                        | 7/100 [00:05<01:12,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  8%|███▍                                       | 8/100 [00:06<01:12,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  9%|███▊                                       | 9/100 [00:07<01:17,  1.18it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 10%|████▏                                     | 10/100 [00:08<01:14,  1.21it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 11%|████▌                                     | 11/100 [00:08<01:12,  1.23it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 12%|█████                                     | 12/100 [00:09<01:10,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 13%|█████▍                                    | 13/100 [00:10<01:09,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 14%|█████▉                                    | 14/100 [00:11<01:07,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 15%|██████▎                                   | 15/100 [00:11<01:05,  1.29it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 16%|██████▋                                   | 16/100 [00:12<01:04,  1.31it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 17%|███████▏                                  | 17/100 [00:13<01:02,  1.32it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 18%|███████▌                                  | 18/100 [00:14<01:01,  1.33it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 19%|███████▉                                  | 19/100 [00:14<01:00,  1.34it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 20%|████████▍                                 | 20/100 [00:15<00:59,  1.35it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 21%|████████▊                                 | 21/100 [00:16<00:58,  1.35it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 22%|█████████▏                                | 22/100 [00:17<00:57,  1.35it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 23%|█████████▋                                | 23/100 [00:17<00:57,  1.34it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 24%|██████████                                | 24/100 [00:18<00:56,  1.35it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 25%|██████████▌                               | 25/100 [00:19<00:55,  1.35it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 26%|██████████▉                               | 26/100 [00:20<00:55,  1.34it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 27%|███████████▎                              | 27/100 [00:20<00:54,  1.34it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 28%|███████████▊                              | 28/100 [00:21<01:01,  1.17it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 29%|████████████▏                             | 29/100 [00:22<00:58,  1.20it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 30%|████████████▌                             | 30/100 [00:23<00:56,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 31%|█████████████                             | 31/100 [00:24<00:53,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 32%|█████████████▍                            | 32/100 [00:24<00:52,  1.30it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 33%|█████████████▊                            | 33/100 [00:25<00:50,  1.32it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 34%|██████████████▎                           | 34/100 [00:26<00:49,  1.33it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 35%|██████████████▋                           | 35/100 [00:27<00:48,  1.34it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 36%|███████████████                           | 36/100 [00:27<00:47,  1.34it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 37%|███████████████▌                          | 37/100 [00:28<00:47,  1.34it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 38%|███████████████▉                          | 38/100 [00:29<00:46,  1.33it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 39%|████████████████▍                         | 39/100 [00:30<00:45,  1.34it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 40%|████████████████▊                         | 40/100 [00:30<00:45,  1.33it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 41%|█████████████████▏                        | 41/100 [00:31<00:44,  1.34it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 42%|█████████████████▋                        | 42/100 [00:32<00:43,  1.35it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 43%|██████████████████                        | 43/100 [00:33<00:42,  1.34it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 44%|██████████████████▍                       | 44/100 [00:33<00:42,  1.33it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 45%|██████████████████▉                       | 45/100 [00:34<00:41,  1.34it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 46%|███████████████████▎                      | 46/100 [00:35<00:43,  1.23it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 47%|███████████████████▋                      | 47/100 [00:36<00:42,  1.26it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 48%|████████████████████▏                     | 48/100 [00:37<00:40,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 49%|████████████████████▌                     | 49/100 [00:37<00:39,  1.30it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 50%|█████████████████████                     | 50/100 [00:38<00:41,  1.19it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 51%|█████████████████████▍                    | 51/100 [00:39<00:39,  1.24it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 52%|█████████████████████▊                    | 52/100 [00:40<00:37,  1.27it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 53%|██████████████████████▎                   | 53/100 [00:40<00:36,  1.29it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 54%|██████████████████████▋                   | 54/100 [00:41<00:35,  1.31it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 55%|███████████████████████                   | 55/100 [00:42<00:34,  1.31it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 56%|███████████████████████▌                  | 56/100 [00:43<00:33,  1.33it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 57%|███████████████████████▉                  | 57/100 [00:44<00:35,  1.22it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 58%|████████████████████████▎                 | 58/100 [00:44<00:33,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 59%|████████████████████████▊                 | 59/100 [00:45<00:32,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 60%|█████████████████████████▏                | 60/100 [00:46<00:30,  1.30it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 61%|█████████████████████████▌                | 61/100 [00:47<00:30,  1.30it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 62%|██████████████████████████                | 62/100 [00:47<00:28,  1.31it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 63%|██████████████████████████▍               | 63/100 [00:48<00:27,  1.33it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 64%|██████████████████████████▉               | 64/100 [00:49<00:27,  1.32it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 65%|███████████████████████████▎              | 65/100 [00:50<00:26,  1.33it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 66%|███████████████████████████▋              | 66/100 [00:51<00:29,  1.16it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 67%|████████████████████████████▏             | 67/100 [00:52<00:27,  1.22it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 68%|████████████████████████████▌             | 68/100 [00:52<00:25,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 69%|████████████████████████████▉             | 69/100 [00:53<00:24,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 70%|█████████████████████████████▍            | 70/100 [00:54<00:22,  1.31it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 71%|█████████████████████████████▊            | 71/100 [00:54<00:21,  1.32it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 72%|██████████████████████████████▏           | 72/100 [00:55<00:21,  1.32it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 73%|██████████████████████████████▋           | 73/100 [00:56<00:20,  1.33it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 74%|███████████████████████████████           | 74/100 [00:57<00:20,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 75%|███████████████████████████████▌          | 75/100 [00:58<00:19,  1.30it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 76%|███████████████████████████████▉          | 76/100 [00:58<00:18,  1.32it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 77%|████████████████████████████████▎         | 77/100 [00:59<00:17,  1.33it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 78%|████████████████████████████████▊         | 78/100 [01:00<00:16,  1.33it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 79%|█████████████████████████████████▏        | 79/100 [01:01<00:16,  1.29it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 80%|█████████████████████████████████▌        | 80/100 [01:01<00:15,  1.30it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 81%|██████████████████████████████████        | 81/100 [01:02<00:14,  1.31it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 82%|██████████████████████████████████▍       | 82/100 [01:03<00:13,  1.32it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 83%|██████████████████████████████████▊       | 83/100 [01:04<00:12,  1.33it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 84%|███████████████████████████████████▎      | 84/100 [01:04<00:11,  1.33it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 85%|███████████████████████████████████▋      | 85/100 [01:05<00:12,  1.23it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 86%|████████████████████████████████████      | 86/100 [01:06<00:11,  1.25it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 87%|████████████████████████████████████▌     | 87/100 [01:07<00:10,  1.28it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 88%|████████████████████████████████████▉     | 88/100 [01:08<00:09,  1.30it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 89%|█████████████████████████████████████▍    | 89/100 [01:08<00:08,  1.31it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 90%|█████████████████████████████████████▊    | 90/100 [01:09<00:07,  1.32it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 91%|██████████████████████████████████████▏   | 91/100 [01:10<00:06,  1.33it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 92%|██████████████████████████████████████▋   | 92/100 [01:11<00:05,  1.34it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 93%|███████████████████████████████████████   | 93/100 [01:11<00:05,  1.34it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 94%|███████████████████████████████████████▍  | 94/100 [01:12<00:04,  1.35it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 95%|███████████████████████████████████████▉  | 95/100 [01:13<00:03,  1.35it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 96%|████████████████████████████████████████▎ | 96/100 [01:14<00:03,  1.32it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 97%|████████████████████████████████████████▋ | 97/100 [01:14<00:02,  1.33it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 98%|█████████████████████████████████████████▏| 98/100 [01:15<00:01,  1.33it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 99%|█████████████████████████████████████████▌| 99/100 [01:16<00:00,  1.34it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|█████████████████████████████████████████| 100/100 [01:16<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores calculation completed and saved to 'model_scores.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from bert_score import score as bert_score\n",
    "\n",
    "rouge = Rouge()\n",
    "\n",
    "def calculate_scores(df, model_column):\n",
    "    results = {\n",
    "        'ROUGE-1': [],\n",
    "        'ROUGE-2': [],\n",
    "        'ROUGE-L': [],\n",
    "        'METEOR': [],\n",
    "        'BLEU': [],\n",
    "        'BERTScore': []\n",
    "    }\n",
    "    \n",
    "    for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        reference = row['highlights']\n",
    "        hypothesis = row[model_column]\n",
    "\n",
    "        reference_tokens = word_tokenize(reference)\n",
    "        hypothesis_tokens = word_tokenize(hypothesis)\n",
    "        \n",
    "        rouge_scores = rouge.get_scores(hypothesis, reference)[0]\n",
    "        results['ROUGE-1'].append(rouge_scores['rouge-1']['f'])\n",
    "        results['ROUGE-2'].append(rouge_scores['rouge-2']['f'])\n",
    "        results['ROUGE-L'].append(rouge_scores['rouge-l']['f'])\n",
    "        \n",
    "        results['METEOR'].append(meteor_score([reference_tokens], hypothesis_tokens))\n",
    "        \n",
    "        results['BLEU'].append(sentence_bleu([reference_tokens], hypothesis_tokens))\n",
    "        \n",
    "        bert_f1 = bert_score([hypothesis], [reference], lang='en', device='cuda')[2].item()\n",
    "        results['BERTScore'].append(bert_f1)\n",
    "    \n",
    "    return results\n",
    "\n",
    "model_columns = ['nemotron-mini', 'gemma2:9b', 'nemotron', 'gemma2:27b']\n",
    "all_scores = {}\n",
    "\n",
    "for model in model_columns:\n",
    "    print(f\"Calculating scores for {model}...\")\n",
    "    all_scores[model] = calculate_scores(df, model)\n",
    "\n",
    "final_results = []\n",
    "\n",
    "for model, scores in all_scores.items():\n",
    "    model_df = pd.DataFrame(scores)\n",
    "    model_df['Model'] = model\n",
    "    final_results.append(model_df)\n",
    "\n",
    "final_df = pd.concat(final_results, ignore_index=True)\n",
    "\n",
    "final_df.to_csv('model_scores.csv', index=False)\n",
    "\n",
    "print(\"Scores calculation completed and saved to 'model_scores.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "70a64126-1843-4827-bdcd-482a25771a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROUGE-1</th>\n",
       "      <th>ROUGE-2</th>\n",
       "      <th>ROUGE-L</th>\n",
       "      <th>METEOR</th>\n",
       "      <th>BLEU</th>\n",
       "      <th>BERTScore</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.286038</td>\n",
       "      <td>5.482661e-155</td>\n",
       "      <td>0.899131</td>\n",
       "      <td>nemotron-mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.423529</td>\n",
       "      <td>0.395869</td>\n",
       "      <td>1.789631e-01</td>\n",
       "      <td>0.894007</td>\n",
       "      <td>nemotron-mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.196684</td>\n",
       "      <td>3.692294e-155</td>\n",
       "      <td>0.851981</td>\n",
       "      <td>nemotron-mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.155649</td>\n",
       "      <td>5.346778e-79</td>\n",
       "      <td>0.865054</td>\n",
       "      <td>nemotron-mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.278481</td>\n",
       "      <td>0.134831</td>\n",
       "      <td>0.253165</td>\n",
       "      <td>0.216525</td>\n",
       "      <td>8.717896e-02</td>\n",
       "      <td>0.863214</td>\n",
       "      <td>nemotron-mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.344086</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.290605</td>\n",
       "      <td>1.650807e-78</td>\n",
       "      <td>0.870599</td>\n",
       "      <td>gemma2:27b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.065041</td>\n",
       "      <td>0.267857</td>\n",
       "      <td>0.278548</td>\n",
       "      <td>8.353142e-02</td>\n",
       "      <td>0.881784</td>\n",
       "      <td>gemma2:27b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.392523</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>0.373832</td>\n",
       "      <td>0.446902</td>\n",
       "      <td>1.196656e-01</td>\n",
       "      <td>0.907781</td>\n",
       "      <td>gemma2:27b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.353982</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.353982</td>\n",
       "      <td>0.430964</td>\n",
       "      <td>9.976449e-02</td>\n",
       "      <td>0.880155</td>\n",
       "      <td>gemma2:27b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.396040</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.336634</td>\n",
       "      <td>0.347138</td>\n",
       "      <td>8.261809e-02</td>\n",
       "      <td>0.886421</td>\n",
       "      <td>gemma2:27b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ROUGE-1   ROUGE-2   ROUGE-L    METEOR           BLEU  BERTScore  \\\n",
       "0    0.348837  0.068182  0.325581  0.286038  5.482661e-155   0.899131   \n",
       "1    0.470588  0.229167  0.423529  0.395869   1.789631e-01   0.894007   \n",
       "2    0.266667  0.076923  0.240000  0.196684  3.692294e-155   0.851981   \n",
       "3    0.153846  0.000000  0.153846  0.155649   5.346778e-79   0.865054   \n",
       "4    0.278481  0.134831  0.253165  0.216525   8.717896e-02   0.863214   \n",
       "..        ...       ...       ...       ...            ...        ...   \n",
       "395  0.344086  0.053571  0.258065  0.290605   1.650807e-78   0.870599   \n",
       "396  0.303571  0.065041  0.267857  0.278548   8.353142e-02   0.881784   \n",
       "397  0.392523  0.171875  0.373832  0.446902   1.196656e-01   0.907781   \n",
       "398  0.353982  0.166667  0.353982  0.430964   9.976449e-02   0.880155   \n",
       "399  0.396040  0.162162  0.336634  0.347138   8.261809e-02   0.886421   \n",
       "\n",
       "             Model  \n",
       "0    nemotron-mini  \n",
       "1    nemotron-mini  \n",
       "2    nemotron-mini  \n",
       "3    nemotron-mini  \n",
       "4    nemotron-mini  \n",
       "..             ...  \n",
       "395     gemma2:27b  \n",
       "396     gemma2:27b  \n",
       "397     gemma2:27b  \n",
       "398     gemma2:27b  \n",
       "399     gemma2:27b  \n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934e351c-30ba-4dde-9bb6-1722dbaba98e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
